version: "3.3"
services:

  api:
    # Training and inference service for time series models.
    # This API service uses FastAPI for handling http requests and
    # Celery for task queues.
    build: ./api
    image: api
    container_name: api
    env_file:
      - ./postgres/.env
    expose:
      - 80
    ports:
      - ${API_PORT}:80

  rabbitmq:
    # Celery message broker.
    restart: always
    build: ./rabbitmq
    image: rabbitmq
    container_name: rabbitmq
    expose:
      - 5672
    volumes:
      - rabbitmq_data:/var/lib/rabbitmq/data

  redis:
    # Celery backend.
    image: redis:latest
    container_name: redis
    expose:
      - 6379

  #  worker:
  #    build: ./worker
  #    image: worker
  #    container_name: worker

  #jupyter:
  #  # `jupyter` container serves jupyterlab services for experimental purposes.
  #  restart: always
  #  build: ./jupyter
  #  image: jupyter
  #  container_name: jupyter
  #  volumes:
  #    - ./jupyter/work:/home/tasks/work
  #  ports:
  #    - ${JUPYTER_PORT}:8888
  #  depends_on:
  #    - mlflow

  postgres:
    restart: always
    build: ./postgres
    image: postgres
    container_name: postgres
    env_file:
      - ./postgres/.env
    expose:
      - 5432
    ports:
      - ${POSTGRES_PORT}:5432
    volumes:
      - pg_data:/var/lib/postgresql/data

  minio:
    build: ./minio
    image: minio
    container_name: minio
    env_file:
      - ./minio/.env
    expose:
      - 9000
      - 9001
    ports:
      - ${MINIO_PORT}:9001

  mlflow:
    build: ./mlflow
    image: mlflow
    container_name: mlflow
    env_file:
      - ./postgres/.env
      - ./mlflow/.env
    expose:
      - 5000
    ports:
      - ${MLFLOW_PORT}:5000
    depends_on:
      - postgres
      - minio

# When you use a named volume like "data:/container/path", you must declare it
# at the docker-compose file. This is not necessary when volumes are host paths.
volumes:
  pg_data:
  rabbitmq_data:
  redis_data:

