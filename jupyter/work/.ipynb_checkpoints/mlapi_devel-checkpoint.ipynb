{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "222c977b-26b2-43ee-926e-24b644b4d9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add mlapi package to sys path\n",
    "\n",
    "MLAPI_PATH = '/home/jovyan/mlapi'\n",
    "\n",
    "import sys\n",
    "\n",
    "if MLAPI_PATH not in sys.path:\n",
    "    sys.path.append(MLAPI_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f5aabd7-6809-45be-9c42-e0599d625e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b40c711d-40f2-4512-af09-32293482592c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f81470-a1c7-47e8-addb-9ace089eefa9",
   "metadata": {},
   "source": [
    "# Json request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b89baa0-42cd-47c2-976d-4c62f6222474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy request.\n",
    "\n",
    "forecaster_data = {\n",
    "    'name': 'sample',\n",
    "    'algorithm': 'seq2seq',\n",
    "    'forecast_horizon': 10,\n",
    "    'perform_hpo': False,\n",
    "    'dataset_name': 'sample',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613f0d19-55a5-43c6-9010-2b1917cbbae1",
   "metadata": {},
   "source": [
    "# ParquetLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68173364-09ee-4afc-b54f-b410173dfbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlapi.celery_app.ml.datasources.s3 import ParquetLoader\n",
    "from mlapi.celery_app.client_args import ClientArgs\n",
    "#from mlapi.main import Forecaster\n",
    "#from minio import Minio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c97c604d-0e88-4776-88d9-004ef2180f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Client args (authentication).\n",
    "\n",
    "client_args = {\n",
    "    \"s3_endpoint\": 'minio:9000',\n",
    "    \"access_key\": 'user',\n",
    "    \"secret_key\": 'password',\n",
    "    'secure': False\n",
    "}\n",
    "client_args = ClientArgs(**client_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5441f854-7901-438f-8792-a5d35e604e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parquet getter: getter for parquet datasets stored in minio buckets.\n",
    "parquet_loader = ParquetLoader(\n",
    "    'sample_project',\n",
    "    'X-train',\n",
    "    client_args\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "27fb0b31-dec5-4598-879a-c37d31eff541",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'target': <pyarrow.parquet.ParquetDataset at 0xffff4f5b5280>}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parquet_loader.load_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381d9dce-ff91-4bb6-8141-5f01642db68c",
   "metadata": {},
   "source": [
    "# ParquetMerger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7b89f839-fd40-4f2c-ad3c-883783f4afc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlapi.ml._parquet_mergers import TimeSeriesMerger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1632204e-cbea-4fbb-a511-80c4145a2a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = parquet_loader.resolve_datasets()\n",
    "merger = TimeSeriesMerger(**datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fe830854-c095-41b3-bd19-4d28e0f28b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = merger.merge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9b05bb8e-268d-4b7a-9045-b1762e53a796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'target': ['target'],\n",
       " 'time_varying_known_reals': [],\n",
       " 'time_varying_unknown_reals': [],\n",
       " 'static_categoricals': []}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merger.get_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615e215a-cec8-431c-b22f-e4383dfc0339",
   "metadata": {},
   "source": [
    "# PreprocessorCreator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e817dc1a-66b8-4c13-9265-608518ee9fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlapi.ml._preprocessor import PreprocessorCreator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3897231f-3a62-4ed2-a516-d4c4e64d6cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_ids = merger.get_group_ids()\n",
    "timestamp = 'timestamp'\n",
    "preprocessor_creator = PreprocessorCreator(group_ids, timestamp)\n",
    "preprocessor = preprocessor_creator.create_preprocessor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70389956-7106-4498-9349-a0e9e63c19f0",
   "metadata": {},
   "source": [
    "# EstimatorCreator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a34158fa-fd8e-47db-b83e-d85e1e1f3d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlapi.ml._estimator import EstimatorCreator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c95c99ac-6935-4bd1-a7fd-5801513dc4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_creator = EstimatorCreator(predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "be95f120-c532-414e-9775-afef93e610a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_time_dependence = merger.get_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b189556a-d18b-4d32-9f69-d30159f22dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = estimator_creator.create_estimator(group_ids, **features_time_dependence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ff89f0-476c-45f8-98a7-634939787936",
   "metadata": {},
   "source": [
    "# Forecasting task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1625f85-794f-412f-879d-102912ec2cd7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from mlapi.celery_app.ml.datasources.s3 import ParquetLoader\n",
    "from mlapi.celery_app.ml.estimator import EstimatorCreator\n",
    "from mlapi.celery_app.ml.parquet_resolver import TimeSeriesResolver\n",
    "from mlapi.celery_app.ml.preprocessor import PreprocessorCreator\n",
    "from mlapi.celery_app.client_args import ClientArgs\n",
    "from mlapi.celery_app.ml.utils.data import AttrDict\n",
    "from mlapi.celery_app.ml.utils.pandas import duplicate_pandas_column\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05508e38-0e1c-4572-b208-5df5d93f1001",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from typing import Optional\n",
    "\n",
    "\n",
    "class User(BaseModel):\n",
    "    username: str\n",
    "    email: Optional[str] = None\n",
    "    full_name: Optional[str] = None\n",
    "    disabled: Optional[bool] = None\n",
    "    access_key: Optional[str] = None\n",
    "    secret_key: Optional[str] = None\n",
    "    s3_endpoint: Optional[str] = None\n",
    "    \n",
    "\n",
    "class Forecaster(BaseModel):\n",
    "    task_name: str\n",
    "    dataset_group_name: str\n",
    "    dataset_name: str\n",
    "    algorithm: str\n",
    "    forecast_horizon: int\n",
    "    perform_hpo: bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8299b767-c42b-4f99-aa71-37405b151079",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CreateForecasterTask:\n",
    "    \"\"\"Loads, preprocess and fits data from s3.\n",
    "    \"\"\"\n",
    "\n",
    "    METRICS = ['train_loss']\n",
    "\n",
    "    def run(self, forecaster_data, user_data):\n",
    "        forecaster = AttrDict(forecaster_data)\n",
    "        user = AttrDict(user_data)\n",
    "\n",
    "        # Load data.\n",
    "        resolved = self._resolve_dataset(forecaster, user)\n",
    "        X = resolved['X']\n",
    "        group_ids = resolved['group_ids']\n",
    "        timestamp = resolved['timestamp']\n",
    "\n",
    "        # Create both preprocessor and estimator.\n",
    "        preprocessor = self._create_preprocessor(group_ids, timestamp)\n",
    "        estimator = self._create_estimator(forecaster, group_ids)\n",
    "        \n",
    "        return preprocessor, X\n",
    "\n",
    "        # Put everything inside a sklearn Pipeline and fit.\n",
    "        pipeline = self._fit_pipeline(X, preprocessor, estimator)\n",
    "        return pipeline, X\n",
    "\n",
    "        # Save metrics\n",
    "        logger = MlFlowLogger()\n",
    "        for metric in self.METRICS:\n",
    "            estimator = pipeline['estimator']\n",
    "            history = get_history(estimator, metric)\n",
    "            logger.save_metric(name=metric, values=history)\n",
    "\n",
    "        # Save model the model with a signature that defines the schema of\n",
    "        # the model's inputs and outputs. When the model is deployed, this\n",
    "        # signature will be used to validate inputs.\n",
    "        wrapped_pipeline = wrap_pipeline(pipeline)\n",
    "        signature = infer_signature(X, wrapped_pipeline.predict(None, X))\n",
    "        logger.save_model(\n",
    "            name=forecaster.task_name, model=wrapped_pipeline,\n",
    "            signature=signature)\n",
    "\n",
    "        # Log all\n",
    "        logger.log_all()\n",
    "\n",
    "    def _fit_pipeline(self, X, preprocessor, estimator):\n",
    "        \"\"\"Collects both `preprocessor` and `estimator` into a single\n",
    "        :class:`sklearn.pipeline.Pipeline` object and fits X.\n",
    "        \"\"\"\n",
    "        steps = [('preprocessor', preprocessor), ('estimator', estimator)]\n",
    "        pipeline = Pipeline(steps)\n",
    "        pipeline.fit(X)\n",
    "        return pipeline\n",
    "\n",
    "    def _create_estimator(self, forecaster, group_ids, callbacks=None):\n",
    "        \"\"\"Creates time series estimator.\n",
    "        \"\"\"\n",
    "        estimator_creator = EstimatorCreator(forecaster)\n",
    "        target = 'target'\n",
    "        time_varying_unknown_reals = ['target']\n",
    "        time_varying_known_reals = []\n",
    "        static_categoricals = []\n",
    "\n",
    "        estimator = estimator_creator.create_estimator(\n",
    "            group_ids, target, time_varying_known_reals,\n",
    "            time_varying_unknown_reals, static_categoricals,\n",
    "            callbacks=callbacks, time_idx='time_index')\n",
    "        return estimator\n",
    "\n",
    "    def _create_preprocessor(self, group_ids, timestamp):\n",
    "        \"\"\"Creates sklearn preprocessor.\n",
    "        \"\"\"\n",
    "        preprocessor_creator = PreprocessorCreator(group_ids, timestamp)\n",
    "        preprocessor = preprocessor_creator.create_preprocessor()\n",
    "        return preprocessor\n",
    "\n",
    "    def _resolve_dataset(self, forecaster, user):\n",
    "        \"\"\"Calls :meth:`resolve` from :class:`TimeSeriesResolver`.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        dict : str -> obj\n",
    "        \"\"\"\n",
    "        client_args = {\n",
    "            \"s3_endpoint\": user.s3_endpoint,\n",
    "            \"access_key\": user.access_key,\n",
    "            \"secret_key\": user.secret_key,\n",
    "            'secure': False\n",
    "        }\n",
    "        client_args = ClientArgs(**client_args)\n",
    "        parquet_loader = ParquetLoader(\n",
    "            forecaster.dataset_group_name, forecaster.dataset_name,\n",
    "            client_args)\n",
    "        datasets = parquet_loader.load_all()\n",
    "        timeseries_resolver = TimeSeriesResolver(**datasets)\n",
    "        return timeseries_resolver.resolve()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36691fdb-bde4-4e7c-a150-588de4366daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_kwargs = {\n",
    "    \"username\": \"johndoe\",\n",
    "    \"full_name\": \"John Doe\",\n",
    "    \"email\": \"johndoe@example.com\",\n",
    "    \"hashed_password\": \"$2b$12$EixZaYVK1fsbw1ZfbX3OXePaWxn96p36WQoeG6Lruj3vjPGga31lW\",\n",
    "    \"access_key\": \"johndoe\",\n",
    "    \"secret_key\": \"password\",\n",
    "    \"s3_endpoint\": \"minio:9000\"\n",
    "}\n",
    "user = User(**user_kwargs)\n",
    "\n",
    "forecaster_kwargs = {\n",
    "    'task_name': 'seq2seq_training',\n",
    "    'dataset_group_name': 'sample_group',\n",
    "    'dataset_name': 'X_train',\n",
    "    'algorithm': 'seq2seq',\n",
    "    'forecast_horizon': 10,\n",
    "    'perform_hpo': False,\n",
    "}\n",
    "forecaster = Forecaster(**forecaster_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "096935b8-8085-4eab-81c9-ba2f5601ecb1",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'target'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m preprocessor, X \u001b[38;5;241m=\u001b[39m \u001b[43mCreateForecasterTask\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mforecaster\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36mCreateForecasterTask.run\u001b[0;34m(self, forecaster_data, user_data)\u001b[0m\n\u001b[1;32m      9\u001b[0m user \u001b[38;5;241m=\u001b[39m AttrDict(user_data)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Load data.\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m resolved \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_resolve_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mforecaster\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m X \u001b[38;5;241m=\u001b[39m resolved[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     14\u001b[0m group_ids \u001b[38;5;241m=\u001b[39m resolved[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgroup_ids\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36mCreateForecasterTask._resolve_dataset\u001b[0;34m(self, forecaster, user)\u001b[0m\n\u001b[1;32m     91\u001b[0m parquet_loader \u001b[38;5;241m=\u001b[39m ParquetLoader(\n\u001b[1;32m     92\u001b[0m     forecaster\u001b[38;5;241m.\u001b[39mdataset_group_name, forecaster\u001b[38;5;241m.\u001b[39mdataset_name,\n\u001b[1;32m     93\u001b[0m     client_args)\n\u001b[1;32m     94\u001b[0m datasets \u001b[38;5;241m=\u001b[39m parquet_loader\u001b[38;5;241m.\u001b[39mload_all()\n\u001b[0;32m---> 95\u001b[0m timeseries_resolver \u001b[38;5;241m=\u001b[39m \u001b[43mTimeSeriesResolver\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdatasets\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m timeseries_resolver\u001b[38;5;241m.\u001b[39mresolve()\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'target'"
     ]
    }
   ],
   "source": [
    "preprocessor, X = CreateForecasterTask().run(forecaster, user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9dc8bea8-8bd1-4877-999d-fb532aff89f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xt = pipeline['preprocessor'].transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b18e7ef3-a62c-4c67-89e2-9a33036aec6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = X.timestamp.values.reshape(-1, 1)\n",
    "c2 = X.target.values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "113965d2-e7b2-46ea-a125-a05ee63c3d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "2cb4f2e2-de63-4e01-bc3d-78a3b5e62007",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt = pipeline['preprocessor']['groups']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "fdea7803-80d9-4ba4-8099-d8a397db56f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = gt._components_getter.get_columns_dtypes(transformed=False)['timestamp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "06d323d3-f001-406c-a22c-a3c87944af30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _stack_arrays(arrays):\n",
    "    try:\n",
    "        return np.hstack(arrays)\n",
    "    except TypeError:\n",
    "        obj_arrays = [arr.astype(object) for arr in arrays]\n",
    "        return np.hstack(obj_arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "1bb53f96-23fa-4ba8-8c52-16c9bd0adc55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1356998400000000000, 45.0],\n",
       "       [1357084800000000000, 53.0],\n",
       "       [1357171200000000000, 65.0],\n",
       "       ...,\n",
       "       [1503619200000000000, 141.0],\n",
       "       [1503705600000000000, 116.0],\n",
       "       [1503792000000000000, 161.0]], dtype=object)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_stack_arrays([c1, c2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "a1ad090a-7ce5-4a45-9f89-41644976b537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    np.hstack((c1, c2))\n",
    "except TypeError:\n",
    "    print('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "200eff62-f3a2-4f24-b86d-ce7d7938cd3a",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "The DTypes <class 'numpy.dtype[float32]'> and <class 'numpy.dtype[datetime64]'> do not have a common DType. For example they cannot be stored in a single array unless the dtype is `object`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [33]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpipeline\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpreprocessor\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minverse_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/pipeline.py:591\u001b[0m, in \u001b[0;36mPipeline._inverse_transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    589\u001b[0m reverse_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mreversed\u001b[39m(\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter()))\n\u001b[1;32m    590\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, _, transform \u001b[38;5;129;01min\u001b[39;00m reverse_iter:\n\u001b[0;32m--> 591\u001b[0m     Xt \u001b[38;5;241m=\u001b[39m \u001b[43mtransform\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minverse_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    592\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Xt\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/mooncake/preprocessing/column_transformer/_transformers.py:171\u001b[0m, in \u001b[0;36mGroupColumnTransformer.inverse_transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m group\u001b[38;5;241m.\u001b[39mempty:\n\u001b[1;32m    169\u001b[0m         inverse_transformer \u001b[38;5;241m=\u001b[39m ColumnTransformerInverseTransformer(\n\u001b[1;32m    170\u001b[0m             column_transformer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_components_getter)\n\u001b[0;32m--> 171\u001b[0m         inv_group \u001b[38;5;241m=\u001b[39m \u001b[43minverse_transformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minverse_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    172\u001b[0m         arrays\u001b[38;5;241m.\u001b[39mappend(inv_group)\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _to_pandas(\n\u001b[1;32m    174\u001b[0m     arrays, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_components_getter, transformed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    175\u001b[0m     inverse_transformer\u001b[38;5;241m=\u001b[39minverse_transformer)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/mooncake/preprocessing/column_transformer/_inverse_transformer.py:49\u001b[0m, in \u001b[0;36mColumnTransformerInverseTransformer.inverse_transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     47\u001b[0m         inv_transforms\u001b[38;5;241m.\u001b[39mappend(inverse_transformed_columns)\n\u001b[0;32m---> 49\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43minv_transforms\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mhstack\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/numpy/core/shape_base.py:345\u001b[0m, in \u001b[0;36mhstack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    343\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _nx\u001b[38;5;241m.\u001b[39mconcatenate(arrs, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    344\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 345\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_nx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: The DTypes <class 'numpy.dtype[float32]'> and <class 'numpy.dtype[datetime64]'> do not have a common DType. For example they cannot be stored in a single array unless the dtype is `object`."
     ]
    }
   ],
   "source": [
    "pipeline['preprocessor'].inverse_transform(Xt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d1174523-ebb3-4967-b551-f90ef88d4f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = merger.merge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "29178486-80f0-4baf-ba65-956736242ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = merger.get_dataset_by_name('target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "86454fb3-23dd-4350-99c8-5dfc96c2c834",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimestampType(timestamp[ms])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.schema.to_arrow_schema().field('timestamp').type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "99e48764-1392-4a04-b84d-b805b70b0d4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__pyx_vtable__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '_export_to_c',\n",
       " '_field',\n",
       " '_import_from_c',\n",
       " 'add_metadata',\n",
       " 'append',\n",
       " 'empty_table',\n",
       " 'equals',\n",
       " 'field',\n",
       " 'field_by_name',\n",
       " 'from_pandas',\n",
       " 'get_all_field_indices',\n",
       " 'get_field_index',\n",
       " 'insert',\n",
       " 'metadata',\n",
       " 'names',\n",
       " 'pandas_metadata',\n",
       " 'remove',\n",
       " 'remove_metadata',\n",
       " 'serialize',\n",
       " 'set',\n",
       " 'to_string',\n",
       " 'types',\n",
       " 'with_metadata']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(ds.schema.to_arrow_schema())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c0bd2e42-9488-4806-aa93-bdeb51d877a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__pyx_vtable__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '_export_to_c',\n",
       " '_field',\n",
       " '_import_from_c',\n",
       " 'add_metadata',\n",
       " 'append',\n",
       " 'empty_table',\n",
       " 'equals',\n",
       " 'field',\n",
       " 'field_by_name',\n",
       " 'from_pandas',\n",
       " 'get_all_field_indices',\n",
       " 'get_field_index',\n",
       " 'insert',\n",
       " 'metadata',\n",
       " 'names',\n",
       " 'pandas_metadata',\n",
       " 'remove',\n",
       " 'remove_metadata',\n",
       " 'serialize',\n",
       " 'set',\n",
       " 'to_string',\n",
       " 'types',\n",
       " 'with_metadata']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(ds.schema.to_arrow_schema())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "35110c1c-fdcb-4339-9a44-4fd2c4e6c3bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__pyx_vtable__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '_export_to_c',\n",
       " '_field',\n",
       " '_import_from_c',\n",
       " 'add_metadata',\n",
       " 'append',\n",
       " 'empty_table',\n",
       " 'equals',\n",
       " 'field',\n",
       " 'field_by_name',\n",
       " 'from_pandas',\n",
       " 'get_all_field_indices',\n",
       " 'get_field_index',\n",
       " 'insert',\n",
       " 'metadata',\n",
       " 'names',\n",
       " 'pandas_metadata',\n",
       " 'remove',\n",
       " 'remove_metadata',\n",
       " 'serialize',\n",
       " 'set',\n",
       " 'to_string',\n",
       " 'types',\n",
       " 'with_metadata']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(merger.get_arrow_schema(ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d346b6a7-911c-4f1e-bae2-f1bb2c178100",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'target': ['target'],\n",
       " 'time_varying_known_reals': [],\n",
       " 'time_varying_unknown_reals': [],\n",
       " 'static_categoricals': []}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merger.get_names()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
