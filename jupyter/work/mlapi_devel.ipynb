{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "222c977b-26b2-43ee-926e-24b644b4d9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add mlapi package to sys path\n",
    "\n",
    "MLAPI_PATH = '/home/jovyan/mlapi'\n",
    "\n",
    "import sys\n",
    "\n",
    "if MLAPI_PATH not in sys.path:\n",
    "    sys.path.append(MLAPI_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f6e07e7-43de-4781-9b94-f7de4a2d787c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f5aabd7-6809-45be-9c42-e0599d625e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b40c711d-40f2-4512-af09-32293482592c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f81470-a1c7-47e8-addb-9ace089eefa9",
   "metadata": {},
   "source": [
    "# Json request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b89baa0-42cd-47c2-976d-4c62f6222474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy request.\n",
    "\n",
    "forecaster_data = {\n",
    "    'name': 'sample',\n",
    "    'algorithm': 'seq2seq',\n",
    "    'forecast_horizon': 10,\n",
    "    'perform_hpo': False,\n",
    "    'dataset_name': 'sample',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613f0d19-55a5-43c6-9010-2b1917cbbae1",
   "metadata": {},
   "source": [
    "# ParquetLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68173364-09ee-4afc-b54f-b410173dfbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlapi.celery_app.ml.datasources.parquet_loader import ParquetLoader, S3ParquetLoader\n",
    "from mlapi.celery_app.client_args import ClientArgs\n",
    "#from mlapi.main import Forecaster\n",
    "#from minio import Minio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c97c604d-0e88-4776-88d9-004ef2180f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Client args (authentication).\n",
    "\n",
    "client_args = {\n",
    "    \"s3_endpoint\": 'minio:9000',\n",
    "    \"access_key\": 'user',\n",
    "    \"secret_key\": 'password',\n",
    "    'secure': False\n",
    "}\n",
    "client_args = ClientArgs(**client_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5441f854-7901-438f-8792-a5d35e604e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parquet getter: getter for parquet datasets stored in minio buckets.\n",
    "s3_parquet_loader = S3ParquetLoader(client_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06ed768f-a951-4592-8d48-737a4d591cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = ['sample_group', 'X_train']\n",
    "t = s3_parquet_loader.load_many('datasets', *args)['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381d9dce-ff91-4bb6-8141-5f01642db68c",
   "metadata": {},
   "source": [
    "# ParquetMerger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7b89f839-fd40-4f2c-ad3c-883783f4afc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlapi.ml._parquet_mergers import TimeSeriesMerger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1632204e-cbea-4fbb-a511-80c4145a2a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = parquet_loader.resolve_datasets()\n",
    "merger = TimeSeriesMerger(**datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fe830854-c095-41b3-bd19-4d28e0f28b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = merger.merge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9b05bb8e-268d-4b7a-9045-b1762e53a796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'target': ['target'],\n",
       " 'time_varying_known_reals': [],\n",
       " 'time_varying_unknown_reals': [],\n",
       " 'static_categoricals': []}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merger.get_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615e215a-cec8-431c-b22f-e4383dfc0339",
   "metadata": {},
   "source": [
    "# PreprocessorCreator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e817dc1a-66b8-4c13-9265-608518ee9fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlapi.ml._preprocessor import PreprocessorCreator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3897231f-3a62-4ed2-a516-d4c4e64d6cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_ids = merger.get_group_ids()\n",
    "timestamp = 'timestamp'\n",
    "preprocessor_creator = PreprocessorCreator(group_ids, timestamp)\n",
    "preprocessor = preprocessor_creator.create_preprocessor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70389956-7106-4498-9349-a0e9e63c19f0",
   "metadata": {},
   "source": [
    "# EstimatorCreator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a34158fa-fd8e-47db-b83e-d85e1e1f3d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlapi.ml._estimator import EstimatorCreator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c95c99ac-6935-4bd1-a7fd-5801513dc4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_creator = EstimatorCreator(predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "be95f120-c532-414e-9775-afef93e610a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_time_dependence = merger.get_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b189556a-d18b-4d32-9f69-d30159f22dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = estimator_creator.create_estimator(group_ids, **features_time_dependence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ff89f0-476c-45f8-98a7-634939787936",
   "metadata": {},
   "source": [
    "# Forecasting task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c1625f85-794f-412f-879d-102912ec2cd7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from mlapi.celery_app.ml.datasources.parquet_loader import S3ParquetLoader, ParquetLoader\n",
    "from mlapi.celery_app.ml.estimator import EstimatorCreator\n",
    "from mlapi.celery_app.ml.parquet_resolver import TimeSeriesResolver\n",
    "from mlapi.celery_app.ml.preprocessor import PreprocessorCreator\n",
    "from mlapi.celery_app.client_args import ClientArgs\n",
    "from mlapi.celery_app.ml.utils.data import AttrDict\n",
    "from mlapi.celery_app.ml.utils.pandas import duplicate_pandas_column\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05508e38-0e1c-4572-b208-5df5d93f1001",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from typing import Optional\n",
    "\n",
    "\n",
    "class User(BaseModel):\n",
    "    username: str\n",
    "    email: Optional[str] = None\n",
    "    full_name: Optional[str] = None\n",
    "    disabled: Optional[bool] = None\n",
    "    access_key: Optional[str] = None\n",
    "    secret_key: Optional[str] = None\n",
    "    s3_endpoint: Optional[str] = None\n",
    "    \n",
    "\n",
    "class Forecaster(BaseModel):\n",
    "    task_name: str\n",
    "    dataset_group_name: str\n",
    "    dataset_name: str\n",
    "    algorithm: str\n",
    "    forecast_horizon: int\n",
    "    perform_hpo: bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8299b767-c42b-4f99-aa71-37405b151079",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CreateForecasterTask:\n",
    "    \"\"\"Loads, preprocess and fits data from s3.\n",
    "    \"\"\"\n",
    "\n",
    "    METRICS = ['train_loss']\n",
    "    DATASETS_BUCKET = 'datasets'\n",
    "\n",
    "    def run(self, forecaster_data, user_data):\n",
    "        forecaster = AttrDict(forecaster_data)\n",
    "        user = AttrDict(user_data)\n",
    "\n",
    "        # Load data.\n",
    "        resolved = self._resolve_dataset(forecaster, user)\n",
    "        X = resolved['X']\n",
    "        group_ids = resolved['group_ids']\n",
    "        timestamp = resolved['timestamp']\n",
    "        target = 'target'\n",
    "\n",
    "        # Create both preprocessor and estimator.\n",
    "        preprocessor = self._create_preprocessor(group_ids, target, timestamp)\n",
    "        estimator = self._create_estimator(forecaster, group_ids)\n",
    "\n",
    "        # Put everything inside a sklearn Pipeline and fit.\n",
    "        pipeline = self._fit_pipeline(X, preprocessor, estimator)\n",
    "\n",
    "        # Save metrics\n",
    "        logger = MlFlowLogger()\n",
    "        for metric in self.METRICS:\n",
    "            estimator = pipeline['estimator']\n",
    "            history = get_history(estimator, metric)\n",
    "            logger.save_metric(name=metric, values=history)\n",
    "\n",
    "        # Save model the model with a signature that defines the schema of\n",
    "        # the model's inputs and outputs. When the model is deployed, this\n",
    "        # signature will be used to validate inputs.\n",
    "        wrapped_pipeline = wrap_pipeline(pipeline)\n",
    "        signature = infer_signature(X, wrapped_pipeline.predict(None, X))\n",
    "        logger.save_python_model(\n",
    "            name='pipeline', python_model=wrapped_pipeline,\n",
    "            signature=signature,\n",
    "            artifacts=self._create_inference_artifacts(forecaster))\n",
    "\n",
    "        # Log all\n",
    "        logger.log_all()\n",
    "\n",
    "    def _fit_pipeline(self, X, preprocessor, estimator):\n",
    "        \"\"\"Collects both `preprocessor` and `estimator` into a single\n",
    "        :class:`sklearn.pipeline.Pipeline` object and fits X.\n",
    "        \"\"\"\n",
    "        steps = [('preprocessor', preprocessor), ('estimator', estimator)]\n",
    "        pipeline = Pipeline(steps)\n",
    "        pipeline.fit(X)\n",
    "        return pipeline\n",
    "\n",
    "    def _create_estimator(self, forecaster, group_ids, callbacks=None):\n",
    "        \"\"\"Creates time series estimator.\n",
    "        \"\"\"\n",
    "        estimator_creator = EstimatorCreator(forecaster)\n",
    "        target = 'target'\n",
    "        time_varying_unknown_reals = ['target']\n",
    "        time_varying_known_reals = []\n",
    "        static_categoricals = []\n",
    "\n",
    "        estimator = estimator_creator.create_estimator(\n",
    "            group_ids, target, time_varying_known_reals,\n",
    "            time_varying_unknown_reals, static_categoricals,\n",
    "            callbacks=callbacks, time_idx='time_index')\n",
    "        return estimator\n",
    "\n",
    "    def _create_preprocessor(self, group_ids, target, timestamp):\n",
    "        \"\"\"Creates sklearn preprocessor.\n",
    "        \"\"\"\n",
    "        preprocessor_creator = PreprocessorCreator(\n",
    "            group_ids, target, timestamp)\n",
    "        preprocessor = preprocessor_creator.create_preprocessor()\n",
    "        return preprocessor\n",
    "\n",
    "    def _resolve_dataset(self, forecaster, user):\n",
    "        \"\"\"Calls :meth:`resolve` from :class:`TimeSeriesResolver`.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        dict : str -> obj\n",
    "        \"\"\"\n",
    "        client_args = {\n",
    "            \"s3_endpoint\": user.s3_endpoint,\n",
    "            \"access_key\": user.access_key,\n",
    "            \"secret_key\": user.secret_key,\n",
    "            'secure': False\n",
    "        }\n",
    "        client_args = ClientArgs(**client_args)\n",
    "        parquet_loader = S3ParquetLoader(client_args)\n",
    "\n",
    "        # Parquet loading.\n",
    "        bucket_name = self.DATASETS_BUCKET\n",
    "        prefix = [forecaster.dataset_group_name, forecaster.dataset_name]\n",
    "        datasets = parquet_loader.load_many(bucket_name, *prefix)\n",
    "\n",
    "        timeseries_resolver = TimeSeriesResolver(**datasets)\n",
    "        return timeseries_resolver.resolve()\n",
    "\n",
    "    def _create_inference_artifacts(self, forecaster):\n",
    "        bucket = 'datasets'\n",
    "        dataset_group_name = forecaster.dataset_group_name\n",
    "        inference_path = \"s3://{}/{}/inference/\".format(bucket,\n",
    "                                                        dataset_group_name)\n",
    "        return {\"inference\": inference_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "36691fdb-bde4-4e7c-a150-588de4366daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_kwargs = {\n",
    "    \"username\": \"johndoe\",\n",
    "    \"full_name\": \"John Doe\",\n",
    "    \"email\": \"johndoe@example.com\",\n",
    "    \"hashed_password\": \"$2b$12$EixZaYVK1fsbw1ZfbX3OXePaWxn96p36WQoeG6Lruj3vjPGga31lW\",\n",
    "    \"access_key\": \"johndoe\",\n",
    "    \"secret_key\": \"password\",\n",
    "    \"s3_endpoint\": \"minio:9000\"\n",
    "}\n",
    "user = User(**user_kwargs)\n",
    "\n",
    "forecaster_kwargs = {\n",
    "    'task_name': 'seq2seq_training',\n",
    "    'dataset_group_name': 'sample_group',\n",
    "    'dataset_name': 'X_train',\n",
    "    'algorithm': 'seq2seq',\n",
    "    'forecast_horizon': 10,\n",
    "    'perform_hpo': False,\n",
    "}\n",
    "forecaster = Forecaster(**forecaster_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "15534078-1894-46d2-b975-26c808d388ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "parquet_loader = ParquetLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3064646c-8b47-47e9-bcfd-ba4ed2c42b21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'target': <pyarrow.parquet._ParquetDatasetV2 at 0xffff2a029fd0>}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference_dataset_name = 'X_test'\n",
    "abs_path = '/tmp/tmpzxx64kx2/artifacts/.'\n",
    "parquet_partition = abs_path.replace('.', inference_dataset_name)\n",
    "parquet_loader.load_many(parquet_partition)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
