# Build an image that can serve mlflow models.
FROM ubuntu:18.04

RUN apt-get -y update && apt-get install -y --no-install-recommends \
         curl \
         nginx \
         ca-certificates \
         bzip2 \
         git-core \
         build-essential \
         cmake \
    && rm -rf /var/lib/apt/lists/*

# Setup miniconda
RUN curl -L https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh >> miniconda.sh
RUN bash ./miniconda.sh -b -p /miniconda && rm ./miniconda.sh
ENV PATH="/miniconda/bin:$PATH"

ENV GUNICORN_CMD_ARGS="--timeout 60 -k gevent"

# Set up the program in the image
WORKDIR /opt/mlflow
RUN pip install mlflow==1.30.0 



                    COPY model_dir/model /opt/ml/model
                    RUN python -c                     'from mlflow.models.container import _install_pyfunc_deps;                    _install_pyfunc_deps(                        "/opt/ml/model",                         install_mlflow=False,                         enable_mlserver=False,                         env_manager="local")'
                    ENV MLFLOW_DISABLE_ENV_CREATION="true"
                    ENV ENABLE_MLSERVER=False
                    

# granting read/write access and conditional execution authority to all child directories 
# and files to allow for deployment to AWS Sagemaker Serverless Endpoints 
# (see https://docs.aws.amazon.com/sagemaker/latest/dg/serverless-endpoints.html)
RUN chmod o+rwX /opt/mlflow/

ENTRYPOINT ["python", "-c", "from mlflow.models import container as C;C._serve('conda')"]
